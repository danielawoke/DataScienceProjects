{
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "d32a9128-dc5b-40e6-994a-2a2167a5b89f",
      "cell_type": "code",
      "source": "from email.mime import text\nimport planetterp\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom datasets import Dataset\nfrom torch.utils.data import DataLoader\nimport torch\nimport evaluate\nfrom transformers import AutoModelForSequenceClassification\nfrom transformers import Trainer, TrainingArguments\n\n\n# fetch professor data\n\nprofessor1 = planetterp.professor(name=\"Michael McCourt\", reviews=True)\nprofessor2 = planetterp.professor(name=\"Samuel Kerstein\", reviews=True)\nprofessor3 = planetterp.professor(name=\"Antong Liu\", reviews=True)\nprofessor4 = planetterp.professor(name=\"Hallie Liberto\", reviews=True)\nprofessor5 = planetterp.professor(name=\"Peter Carruthers\", reviews=True)\n\n# Tokenizing data of professors\n\ndata = []\n\nfor prof in [professor1, professor2, professor3, professor4, professor5]:\n    for review in prof[\"reviews\"]:\n        data.append({\n            \"text\": review['review'],\n            \"label\": float(review['rating'])\n        })\n\n\nmodel_name = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n\ndataset = Dataset.from_list(data)\n\n\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n\ntokenized = dataset.map(tokenize, batched=True)\ntokenized = tokenized.rename_column(\"label\", \"labels\")\ntokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n\n#splitng dataset\n\nsplit_datasets = dataset.train_test_split(test_size=0.2) \n\ntrain_dataset = split_datasets['train']\ntest_dataset = split_datasets['test']\n\ntokenized_train = train_dataset.map(tokenize, batched=True)\ntokenized_eval = test_dataset.map(tokenize, batched=True)\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\neval_loader = DataLoader(test_dataset, batch_size=8)\n\n# Setting up optimizer\n\n\n# Loading model\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=1)\n\n# Training the model\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=10,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=64,\n    warmup_steps=500,\n    weight_decay=1,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    learning_rate=4e-3,             \n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_train,\n    eval_dataset=tokenized_eval,\n)\n\ntrainer.train()\n\n# Evaluating the model\n\nmetrics = trainer.evaluate()\n\nprint(\"Evaluation metrics:\")\n\nprint(metrics)\n\ndef predict_review(review_text):\n    inputs = tokenizer(\n        review_text,\n        padding=True,\n        truncation=True,\n        return_tensors=\"pt\"\n    )\n\n    inputs.pop(\"token_type_ids\", None)\n    inputs = {k: v.cuda() for k, v in inputs.items()}\n    \n\n    \n    with torch.no_grad(): \n        outputs = model(**inputs)\n\n    prediction = outputs.logits.squeeze().item()\n    return prediction\n\n# Example prediction\n\nmodel = model.cuda()\nBadReviewText = \"The workload was quite heavy, really didn't like this professor. Dont take him.\"\nGoodReviewText = \"This professor was amazing! Loved the way he taught and made the class engaging.\"\nBadReview = predict_review(BadReviewText)\nprint(f\"Predicted rating for the Bad review: {BadReview}\")\nGoodReview = predict_review(GoodReviewText)\nprint(f\"Predicted rating for the Good review: {GoodReview}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}